{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import libraries","metadata":{"id":"lKqhWrPLZY37"}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator \nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, Activation,GlobalMaxPooling2D,GlobalAveragePooling2D,BatchNormalization\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nimport tensorflow.keras.backend as keras_backend","metadata":{"id":"Ket4idSTZKge","execution":{"iopub.status.busy":"2021-10-09T18:32:00.833926Z","iopub.execute_input":"2021-10-09T18:32:00.834227Z","iopub.status.idle":"2021-10-09T18:32:00.845879Z","shell.execute_reply.started":"2021-10-09T18:32:00.834198Z","shell.execute_reply":"2021-10-09T18:32:00.844616Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"# Download and unzip data","metadata":{"id":"8iJNvOK6aGIm"}},{"cell_type":"code","source":"!wget https://www.dropbox.com/s/t4pzwpvrzneb190/training_set.zip\n!wget https://www.dropbox.com/s/i37jfni3d29raoc/test_set.zip","metadata":{"id":"olg0rsOeaFgv","execution":{"iopub.status.busy":"2021-10-09T17:57:50.992741Z","iopub.execute_input":"2021-10-09T17:57:50.993625Z","iopub.status.idle":"2021-10-09T17:58:10.765410Z","shell.execute_reply.started":"2021-10-09T17:57:50.993577Z","shell.execute_reply":"2021-10-09T17:58:10.764183Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!unzip -o training_set.zip \n!unzip -o test_set.zip","metadata":{"id":"X0lzgUa7aMu2","execution":{"iopub.status.busy":"2021-10-09T18:01:57.495188Z","iopub.execute_input":"2021-10-09T18:01:57.495880Z","iopub.status.idle":"2021-10-09T18:02:08.696559Z","shell.execute_reply.started":"2021-10-09T18:01:57.495826Z","shell.execute_reply":"2021-10-09T18:02:08.695541Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Parameters for the project","metadata":{"id":"I7MRNp15bmOU"}},{"cell_type":"code","source":"img_w,img_h= 150,150\ntraining_dir = r\"training_set/training_set\"\nvalidation_dir=r\"test_set/test_set\"\nepochs= 20\nbatch_size=20\n","metadata":{"id":"viIgKlZ8brSR","execution":{"iopub.status.busy":"2021-10-09T19:25:44.317907Z","iopub.execute_input":"2021-10-09T19:25:44.318217Z","iopub.status.idle":"2021-10-09T19:25:44.324074Z","shell.execute_reply.started":"2021-10-09T19:25:44.318188Z","shell.execute_reply":"2021-10-09T19:25:44.322791Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"markdown","source":"# Creating Image data generators with Augmentation\n","metadata":{"id":"v1JOy_pTbLkW"}},{"cell_type":"code","source":"# \ntrain_datagen=ImageDataGenerator ( rescale=1. /255,shear_range =0.2,zoom_range=0.2,horizontal_flip =True)\ntest_datagen=ImageDataGenerator (rescale=1. /255)\n\ntrain_generator =train_datagen.flow_from_directory(training_dir,target_size =(img_w,img_h), batch_size=batch_size,class_mode='binary',classes=['cats','dogs'])\nvalidation_generator =test_datagen.flow_from_directory(validation_dir,target_size =(img_w,img_h), batch_size=batch_size,class_mode='binary')\n","metadata":{"id":"bJn5icIEaShs","outputId":"f7aa335d-3cdf-442e-d466-a1ddc5b89fdb","execution":{"iopub.status.busy":"2021-10-09T19:30:17.962431Z","iopub.execute_input":"2021-10-09T19:30:17.962820Z","iopub.status.idle":"2021-10-09T19:30:18.832761Z","shell.execute_reply.started":"2021-10-09T19:30:17.962777Z","shell.execute_reply":"2021-10-09T19:30:18.831695Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"if keras_backend.image_data_format()=='channels_first': \n    input_shape=(3, img_w, img_h)\nelse:\n    input_shape=(img_w,img_h,3)","metadata":{"id":"2ZNX2nw_cycp","execution":{"iopub.status.busy":"2021-10-09T19:30:31.968935Z","iopub.execute_input":"2021-10-09T19:30:31.969305Z","iopub.status.idle":"2021-10-09T19:30:31.975549Z","shell.execute_reply.started":"2021-10-09T19:30:31.969275Z","shell.execute_reply":"2021-10-09T19:30:31.974457Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"markdown","source":"# Display data from each batch of data generators","metadata":{"id":"EMDuyCKgdP5C"}},{"cell_type":"code","source":"plt.figure(figsize=(12, 12))\nfor i in range(0, 15):\n    plt.subplot(5, 3, i+1)\n    for X_batch, Y_batch in train_generator:\n        # print(Y_batch)\n        image = X_batch[0] #sampling first image from each batch\n        if Y_batch[0] == 0.0:\n            plt.xlabel(\"Cat\")\n        else:\n            plt.xlabel(\"Dog\")\n        plt.imshow(image)\n        break\nplt.tight_layout()\nplt.show()","metadata":{"id":"T-kRlBfNc6Lb","outputId":"bc6d6d93-065a-4c85-be1f-ec04145eba55","execution":{"iopub.status.busy":"2021-10-09T19:30:34.378893Z","iopub.execute_input":"2021-10-09T19:30:34.379653Z","iopub.status.idle":"2021-10-09T19:30:39.160432Z","shell.execute_reply.started":"2021-10-09T19:30:34.379596Z","shell.execute_reply":"2021-10-09T19:30:39.159239Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"markdown","source":"# Pretrained model building","metadata":{"id":"UhDhuYKHeGwQ"}},{"cell_type":"code","source":"from tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.models import Model","metadata":{"id":"Ngfuo6todX-_","execution":{"iopub.status.busy":"2021-10-09T19:30:44.027493Z","iopub.execute_input":"2021-10-09T19:30:44.028662Z","iopub.status.idle":"2021-10-09T19:30:44.037833Z","shell.execute_reply.started":"2021-10-09T19:30:44.028629Z","shell.execute_reply":"2021-10-09T19:30:44.036519Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"code","source":"pretrained_model= MobileNetV2(include_top=False,weights='imagenet',input_shape=input_shape)","metadata":{"id":"2RKyPYmtecrr","execution":{"iopub.status.busy":"2021-10-09T19:30:45.648463Z","iopub.execute_input":"2021-10-09T19:30:45.649307Z","iopub.status.idle":"2021-10-09T19:30:46.980330Z","shell.execute_reply.started":"2021-10-09T19:30:45.649273Z","shell.execute_reply":"2021-10-09T19:30:46.979263Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"code","source":"print('no of layers:> ',len(pretrained_model.layers))\n\nlayer_list = [layers.name for layers in pretrained_model.layers]\n# print(layer_list)\n# print('Index of the first layer of block 7:>  ',layer_list.index(\"block7a_expand_conv\"))\n\n# make all the block till 352 as non-trainable\nfor layers in pretrained_model.layers:\n    layers.trainable = False\n\n# make all the block from 353 as trainable\n# for layers in pretrained_model.layers:\n#     if layers._keras_api_names[0] == 'keras.layers.BatchNormalization':\n#         layers.trainable = False\n\nlast_layer = pretrained_model.get_layer('out_relu') #final layer\nlast_output = last_layer.output\n\n# Adding the head to the pretrained model\nx = GlobalMaxPooling2D()(last_output)\nx = BatchNormalization()(x)\n# x = Dropout(0.2, name=\"top_dropout\")(x)\n# x = Dense(256, activation=\"relu\")(x)\n# x = Dense(128, activation=\"relu\")(x)\n# x = Dense(64, activation=\"relu\")(x)\n# x = Dense(32, activation=\"relu\")(x)\nx = Dense(1, activation=\"sigmoid\", name=\"pred\")(x)\nMobilenet_v2_model = Model(pretrained_model.input, x)\n\n# Mobilenet_v2_model.summary()\n","metadata":{"id":"rY8holL4fSUb","outputId":"0a4a7db2-43ad-47d6-b2e5-38e86250e3a0","execution":{"iopub.status.busy":"2021-10-09T19:35:07.042936Z","iopub.execute_input":"2021-10-09T19:35:07.043250Z","iopub.status.idle":"2021-10-09T19:35:07.107653Z","shell.execute_reply.started":"2021-10-09T19:35:07.043220Z","shell.execute_reply":"2021-10-09T19:35:07.106342Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"markdown","source":"# Checking how many layers are trainable","metadata":{"id":"ye5MID6xFRwO"}},{"cell_type":"code","source":"# for layers in Efficientnet_model.layers:\n#     print(layers._keras_api_names,\"> \",layers.trainable)","metadata":{"id":"aupEiUDw5cUY","execution":{"iopub.status.busy":"2021-10-09T19:35:08.373506Z","iopub.execute_input":"2021-10-09T19:35:08.373807Z","iopub.status.idle":"2021-10-09T19:35:08.378840Z","shell.execute_reply.started":"2021-10-09T19:35:08.373777Z","shell.execute_reply":"2021-10-09T19:35:08.377836Z"},"trusted":true},"execution_count":129,"outputs":[]},{"cell_type":"markdown","source":"# Compiling and fitting the model","metadata":{"id":"B3GZZIptrxir"}},{"cell_type":"code","source":"earlystop = EarlyStopping(patience=10)\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n                                            patience=2, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)\n\ncallbacks = [earlystop, learning_rate_reduction]\n\nMobilenet_v2_model.compile(loss='binary_crossentropy',\n              optimizer=optimizers.Adam(learning_rate=0.001),\n              metrics=['accuracy'])","metadata":{"id":"BGtrEfXKisZ6","execution":{"iopub.status.busy":"2021-10-09T19:35:09.455444Z","iopub.execute_input":"2021-10-09T19:35:09.456271Z","iopub.status.idle":"2021-10-09T19:35:09.481973Z","shell.execute_reply.started":"2021-10-09T19:35:09.456237Z","shell.execute_reply":"2021-10-09T19:35:09.480952Z"},"trusted":true},"execution_count":130,"outputs":[]},{"cell_type":"code","source":"training = Mobilenet_v2_model.fit(train_generator,\n                   steps_per_epoch=100,epochs=50,\n                   validation_data=validation_generator,\n                       validation_steps=100,callbacks=callbacks)","metadata":{"id":"iSLtEOfeisVv","outputId":"22200d8f-aefb-4ab6-bfcb-d006b292f565","execution":{"iopub.status.busy":"2021-10-09T19:57:55.582231Z","iopub.execute_input":"2021-10-09T19:57:55.582922Z","iopub.status.idle":"2021-10-09T20:03:49.017142Z","shell.execute_reply.started":"2021-10-09T19:57:55.582889Z","shell.execute_reply":"2021-10-09T20:03:49.015774Z"},"trusted":true},"execution_count":141,"outputs":[]},{"cell_type":"markdown","source":"# Visualization","metadata":{"id":"2olcmQ3S01Do"}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n# list all data in training\nprint(training.history.keys())\n# summarize training for accuracy\nplt.plot(training.history['accuracy'])\nplt.plot(training.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize traning for loss\nplt.plot(training.history['loss'])\nplt.plot(training.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"id":"6MBBaOIrisTh","execution":{"iopub.status.busy":"2021-10-09T20:03:49.020350Z","iopub.execute_input":"2021-10-09T20:03:49.020741Z","iopub.status.idle":"2021-10-09T20:03:49.541352Z","shell.execute_reply.started":"2021-10-09T20:03:49.020699Z","shell.execute_reply":"2021-10-09T20:03:49.540351Z"},"trusted":true},"execution_count":142,"outputs":[]},{"cell_type":"markdown","source":"# Prediction","metadata":{"id":"3K-5BJzA0yQ8"}},{"cell_type":"code","source":"Mobilenet_v2_model.evaluate(validation_generator)","metadata":{"execution":{"iopub.status.busy":"2021-10-09T20:06:03.645460Z","iopub.execute_input":"2021-10-09T20:06:03.645779Z","iopub.status.idle":"2021-10-09T20:06:10.339630Z","shell.execute_reply.started":"2021-10-09T20:06:03.645751Z","shell.execute_reply":"2021-10-09T20:06:10.338520Z"},"trusted":true},"execution_count":145,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing import image\nimport numpy as np\nimg_pred = image.load_img(\"test_set/test_set/dogs/dog.4003.jpg\",target_size=(150,150))\n\nimg_pred=image.img_to_array(img_pred)\nimg_pred=np.expand_dims(img_pred, axis=0)\n\nresult = Efficientnet_model.predict(img_pred)\nprint(result)\nif result[0][0]==1:\n    prediction =\"Dog\"\nelse:\n    prediction =\"Cat\"\nprint('Prediction: ',prediction)\n\nimg=mpimg.imread('test_set/test_set/dogs/dog.4006.jpg')\nimgplot = plt.imshow(img)\nplt.show()\n","metadata":{"id":"XGbjjUWHisRM","outputId":"3557d17b-7329-4add-9d75-e1f0bde4c8bf","execution":{"iopub.status.busy":"2021-10-09T20:04:43.093305Z","iopub.execute_input":"2021-10-09T20:04:43.093840Z","iopub.status.idle":"2021-10-09T20:04:45.715775Z","shell.execute_reply.started":"2021-10-09T20:04:43.093799Z","shell.execute_reply":"2021-10-09T20:04:45.714591Z"},"trusted":true},"execution_count":144,"outputs":[]},{"cell_type":"markdown","source":"# Explanations\n\n* As a part of assignment 2, I went for pre-trained MobileNet-V2 model with the Top= False and added custom head to the model.\n* Removed the drop_out layer as the model was underfitting because of the drop_out.\n* Tried adding \"softmax\" instead of \"sigmoid\" activation function but that lead to decrease in accuracy.\n* Increase in epoch didn't have much effect on the accuracy as the model reached it's peak accuracy and training stopped early.\n* Updated from SGD optimizer to Adam which boosted the accuracy.\n\n* **Finally achived the test accuracy of 95.79%**","metadata":{}},{"cell_type":"code","source":"","metadata":{"id":"m7RqaI2SisOj"},"execution_count":null,"outputs":[]}]}